{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ccdc7fd6eb57534",
   "metadata": {},
   "source": [
    "# Driver and engine performance impact on F1 race results\n",
    "\n",
    "Łukasz Filo, Klaudiusz Grobelski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf3371f79e509c",
   "metadata": {},
   "source": [
    "## Problem formulation [0-5 pts]:\n",
    "\n",
    "- is the problem clearly stated [1 pt]\n",
    "- what is the point of creating model, are potential use cases defined [1 pt]\n",
    "- where do data comes from, what does it containt [1 pt]\n",
    "- DAG has been drawn [1 pt]\n",
    "- confoundings (pipe, fork, collider) were described [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d6ae3b36a3cdf",
   "metadata": {},
   "source": [
    "In this notebook, we will develop a Bayesian multilevel binomial regression model to predict driver performance across recent Formula 1 seasons. Specifically, we will use data from the 2019–2024 seasons. The input data includes information about drivers, constructors, and engine suppliers used by each team. The primary objective of this analysis is to understand and predict how various factors—such as driver skill, team changes, and engine suppliers—affect driver performance over time. This model could assist teams in making strategic decisions, such as evaluating whether changes in drivers or engine suppliers might enhance performance. It may also be valuable to fans and analysts seeking to assess the relative impact of technical and human factors on race results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ccc5f1",
   "metadata": {},
   "source": [
    "We use historical race data sourced from FastF1, which includes finishing positions, lap times, and team-driver pairings for each race. Driver skill ratings are obtained from the EA Sports F1 game, while engine usage data (i.e., which power unit each constructor used in a given season) is collected from Wikipedia, covering the 2019–2024 period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd831891d73c306a",
   "metadata": {},
   "source": [
    "To gain a clearer understanding of the relationships between variables and to identify potential sources of bias, we will construct a Directed Acyclic Graph (DAG). The DAG will include nodes such as Driver Skill, Team, Engine, and Performance, and will help visualize dependencies and causal paths within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b40d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:02:30.005736Z",
     "start_time": "2025-05-15T15:02:29.974122Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/model_1_DAG.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1375c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:02:30.108920Z",
     "start_time": "2025-05-15T15:02:30.097468Z"
    }
   },
   "outputs": [],
   "source": [
    "Image(\"images/model_2_DAG.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49162b1bf0b775e8",
   "metadata": {},
   "source": [
    "DAGs illustrate the main types of confounding structures:\n",
    "\n",
    " - Forks: Present in both models where multiple variables (e.g., `α`, `constructor`, `β`, `engine`) influence the same downstream node (the linear model).\n",
    "\n",
    "- Pipes: Clear in the chain `model` → `θ` → `y`, representing a direct causal path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4393ef1f88c5b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T12:44:54.650818Z",
     "start_time": "2025-05-25T12:44:54.639777Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cmdstanpy import CmdStanModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# import logging\n",
    "# logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a52c401ca73b3",
   "metadata": {},
   "source": [
    "## Data preprocessing [0-2 pts]:\n",
    "- is preprocessing step clearly described [1 pt]\n",
    "- reasoning and types of actions taken on the dataset have been described [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811aaeb56d621a8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:02:30.970942Z",
     "start_time": "2025-05-15T15:02:30.967254Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed_data/data.csv')\n",
    "unique_drivers = df['DriverId'].unique()\n",
    "driver_id_map = {driver: idx + 1 for idx, driver in enumerate(unique_drivers)}\n",
    "df['DriverId'] = df['DriverId'].map(driver_id_map)\n",
    "drivers = df['DriverId'].values\n",
    "\n",
    "unique_team = df['TeamId'].unique()\n",
    "team_id_map = {team: idx + 1 for idx, team in enumerate(unique_team)}\n",
    "df['TeamId'] = df['TeamId'].map(team_id_map)\n",
    "teams = df['TeamId'].values\n",
    "\n",
    "unique_engine = df['Engine'].unique()\n",
    "engine_id_map = {engine: idx + 1 for idx, engine in enumerate(unique_engine)}\n",
    "df['Engine'] = df['Engine'].map(engine_id_map)\n",
    "engines = df['Engine'].values\n",
    "\n",
    "unique_season = df['Season'].unique()\n",
    "season_id_map = {season: idx + 1 for idx, season in enumerate(unique_season)}\n",
    "df['Season'] = df['Season'].map(season_id_map)\n",
    "seasons = df['Season'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_group(group):\n",
    "    mean = group['Rating'].mean()\n",
    "    std = group['Rating'].std()\n",
    "    group['Rating'] = (group['Rating'] - mean) / std\n",
    "    return group\n",
    "\n",
    "\n",
    "df = df.groupby('Season', group_keys=False, observed=True).apply(standardize_group)\n",
    "ratings = df[\"Rating\"].values\n",
    "df['Position'] = df['Position'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0105a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_col = ['DriverId', 'Rating', 'TeamId', 'Engine', 'Season','Position']\n",
    "df = df[order_col]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29694a230c753ff3",
   "metadata": {},
   "source": [
    "## Model [0-4 pts]\n",
    "- are two different models specified [1 pt]\n",
    "- are difference between two models explained [1 pt]\n",
    "- is the difference in the models justified (e.g. does adding aditional parameter makes sense? ) [1 pt]\n",
    "- are models sufficiently described (what are formulas, what are parameters, what data are required ) [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9f037",
   "metadata": {},
   "source": [
    "### Model 1: Yearly driver rating and team performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc8d15d6ae7cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:02:30.986477Z",
     "start_time": "2025-05-15T15:02:30.982960Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e205422cd919ffdf",
   "metadata": {},
   "source": [
    "## Priors [0-4 pts]\n",
    "- Is it explained why particular priors for parameters were selected [1 pt]\n",
    "- Have prior predictive checks been done for parameters (are parameters simulated from priors make sense) [1 pt]\n",
    "- Have prior predictive checks been done for measurements (are measurements simulated from priors make sense) [1 pt]\n",
    "- How prior parameters were selected [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e523e4",
   "metadata": {},
   "source": [
    "## The Prior tests were prepared for the best, average, and weakest driver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d35b4d",
   "metadata": {},
   "source": [
    "### Model 1 PPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_ppc = CmdStanModel(stan_file='stan/model_1_ppc.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4638eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plots_ppc_model_1(sigmas, driver_rating):\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "    colors = [\"#130582\", \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "\n",
    "    for s_i in range(3):\n",
    "        sigma = {'sigma': sigmas[s_i], 'driver_rating': driver_rating}\n",
    "        model_1_ppc_sim = model_1_ppc.sample(data=sigma, iter_warmup=1, fixed_param=True, seed=25062025)\n",
    "        \n",
    "        axes[s_i, 0].hist(model_1_ppc_sim.stan_variable('alpha_driver').flatten(), bins=100, density=True, color=colors[1], alpha=0.8)\n",
    "        axes[s_i, 0].set_yticks([])\n",
    "        axes[s_i, 0].set_title(f'alpha_driver ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 1].hist(model_1_ppc_sim.stan_variable('constructor').flatten(), bins=100, density=True, color=colors[2], alpha=0.8)\n",
    "        axes[s_i, 1].set_yticks([])\n",
    "        axes[s_i, 1].set_title(f'constructor ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 2].hist(model_1_ppc_sim.stan_variable('theta').flatten(), bins=100, density=True, color=colors[4], alpha=0.8)\n",
    "        axes[s_i, 2].set_yticks([])\n",
    "        axes[s_i, 2].set_title('theta = constructor - alpha_driver * driver_rating', fontweight='bold')\n",
    "\n",
    "        positions = model_1_ppc_sim.stan_variable('y_ppc').flatten() + 1\n",
    "        n_bins = np.arange(22) - 0.5\n",
    "        axes[s_i, 3].hist(positions, bins=n_bins, rwidth=0.85, density=True, color=colors[5], alpha=0.85, label=\"Simulated Positions\")\n",
    "        axes[s_i, 3].set_xticks(range(22))\n",
    "        axes[s_i, 3].set_xlim([0, 21])\n",
    "        axes[s_i, 3].set_yticks([])\n",
    "        axes[s_i, 3].set_title('Position', fontweight='bold')\n",
    "\n",
    "    for i in range(4):\n",
    "        axes[2, i].set_xlabel(['alpha_driver', 'year_constructor', 'theta', 'Position'][i], fontsize=13, fontweight='bold')\n",
    "\n",
    "    for ax_row in axes:\n",
    "        for ax in ax_row:\n",
    "            ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "    fig.suptitle(\"Prior Predictive Checks for Model 1\", fontsize=18, fontweight='bold')\n",
    "    fig.tight_layout(pad=2.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dcc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = [0.8, 1, 1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e65ae3",
   "metadata": {},
   "source": [
    "#### The driver with the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0569e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_rating = 2.2\n",
    "\n",
    "draw_plots_ppc_model_1(sigmas, driver_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadbd4a8",
   "metadata": {},
   "source": [
    "#### The driver with the average results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_rating = 0\n",
    "\n",
    "draw_plots_ppc_model_1(sigmas, driver_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6974ec",
   "metadata": {},
   "source": [
    "#### The driver with the weakest results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50570435",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_rating = -3\n",
    "\n",
    "draw_plots_ppc_model_1(sigmas, driver_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203d85b",
   "metadata": {},
   "source": [
    "### Model 2 PPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076aeea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_ppc = CmdStanModel(stan_file='stan/model_2_ppc.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plots_ppc_model_2(sigmas, driver_rating):\n",
    "    fig, axes = plt.subplots(3, 5, figsize=(24, 15))\n",
    "    colors = [\"#130582\", \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "\n",
    "    for s_i in range(3):\n",
    "        sigma = {'sigma': sigmas[s_i], 'driver_rating': driver_rating}\n",
    "        model_2_ppc_sim = model_2_ppc.sample(data=sigma, iter_warmup=1, fixed_param=True, seed=25062025)\n",
    "\n",
    "        axes[s_i, 0].hist(model_2_ppc_sim.stan_variable('engine').flatten(), bins=100, density=True, color=colors[0], alpha=0.8)\n",
    "        axes[s_i, 0].set_yticks([])\n",
    "        axes[s_i, 0].set_title(f'engine ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 1].hist(model_2_ppc_sim.stan_variable('alpha_driver').flatten(), bins=100, density=True, color=colors[1], alpha=0.8)\n",
    "        axes[s_i, 1].set_yticks([])\n",
    "        axes[s_i, 1].set_title(f'alpha_driver ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 2].hist(model_2_ppc_sim.stan_variable('year_constructor').flatten(), bins=100, density=True, color=colors[2], alpha=0.8)\n",
    "        axes[s_i, 2].set_yticks([])\n",
    "        axes[s_i, 2].set_title(f'year_constructor ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 3].hist(model_2_ppc_sim.stan_variable('theta').flatten(), bins=100, density=True, color=colors[4], alpha=0.8)\n",
    "        axes[s_i, 3].set_yticks([])\n",
    "        axes[s_i, 3].set_title('theta = engine + alpha_constructor_year \\n - alpha_driver * driver_rating', fontweight='bold')\n",
    "\n",
    "        positions = model_2_ppc_sim.stan_variable('y_ppc').flatten() + 1\n",
    "        n_bins = np.arange(22) - 0.5\n",
    "        axes[s_i, 4].hist(positions, bins=n_bins, rwidth=0.85, density=True, color=colors[5], alpha=0.85, label=\"Simulated Positions\")\n",
    "        axes[s_i, 4].set_xticks(range(22))\n",
    "        axes[s_i, 4].set_xlim([0, 21])\n",
    "        axes[s_i, 4].set_yticks([])\n",
    "        axes[s_i, 4].set_title('Position', fontweight='bold')\n",
    "\n",
    "    for i in range(5):\n",
    "        axes[2, i].set_xlabel(['engine', 'alpha_driver', 'year_constructor', 'theta', 'Position'][i], fontsize=13, fontweight='bold')\n",
    "\n",
    "    for ax_row in axes:\n",
    "        for ax in ax_row:\n",
    "            ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "    fig.suptitle(\"Prior Predictive Checks for Model 2\", fontsize=18, fontweight='bold')\n",
    "    fig.tight_layout(pad=2.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ca378",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = [0.8, 1, 1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ace57",
   "metadata": {},
   "source": [
    "#### The driver with the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0aaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_rating = 2.2\n",
    "\n",
    "draw_plots_ppc_model_2(sigmas, driver_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9364e",
   "metadata": {},
   "source": [
    "#### An average driver from the middle of the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3965e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_rating = 0\n",
    "\n",
    "draw_plots_ppc_model_2(sigmas, driver_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4985b",
   "metadata": {},
   "source": [
    "#### The driver with the worst results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_rating = -3\n",
    "\n",
    "draw_plots_ppc_model_2(sigmas, driver_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc53b3",
   "metadata": {},
   "source": [
    "We choose sigma 1.0 for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c00465f2c09d6",
   "metadata": {},
   "source": [
    "## Posterior analysis (model 1) [0-4 pts]\n",
    "- were there any issues with the sampling? if there were what kind of ideas for mitigation were used [1 pt]\n",
    "- are the samples from posterior predictive distribution analyzed [1 pt]\n",
    "- are the data consistent with posterior predictive samples and is it sufficiently commented (if they are not then is the justification provided)\n",
    "have parameter marginal disrtibutions been analyzed (histograms of individual parametes plus summaries, are they diffuse or concentrated, what can we say about values) [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7eeb71ba70340e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:02:31.179823Z",
     "start_time": "2025-05-15T15:02:31.173970Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1 = CmdStanModel(stan_file='stan/model_1.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6515e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_data = {'N': len(df),\n",
    "                'C': len([*team_id_map.values()]),\n",
    "                'D': len([*driver_id_map.values()]),\n",
    "                'driver_rating': ratings,\n",
    "                'constructor': teams,                \n",
    "                'driver': drivers,\n",
    "                'position': df['Position'] - 1} \n",
    "\n",
    "model_1_fit = model_1.sample(data=model_1_data, seed=25062025, iter_warmup=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e811405",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_names = ['hamilton', 'norris', 'leclerc']\n",
    "fig, axes = plt.subplots(1, len(drivers_names), figsize=(5 * len(drivers_names), 4), sharey=True)\n",
    "\n",
    "n_bins = np.arange(22) - 0.5\n",
    "\n",
    "for d_i, d_name in enumerate(drivers_names):\n",
    "    ax = axes[d_i]\n",
    "    driver_id = driver_id_map[d_name]\n",
    "    results = df[df['DriverId'] == driver_id]\n",
    "    results_idx = results.index\n",
    "\n",
    "    ax.hist((results['Position']).tolist(),\n",
    "            bins=n_bins,\n",
    "            rwidth=0.9,\n",
    "            histtype='step',\n",
    "            edgecolor='black',\n",
    "            density=True,\n",
    "            label='Observed')\n",
    "\n",
    "    ax.hist(model_1_fit.stan_variable('y_hat').T[results_idx].flatten() + 1,\n",
    "            bins=n_bins,\n",
    "            rwidth=0.9,\n",
    "            color='cornflowerblue',\n",
    "            edgecolor='royalblue',\n",
    "            alpha=0.7,\n",
    "            density=True,\n",
    "            label='Simulated')\n",
    "\n",
    "    ax.set_xticks(range(22))\n",
    "    ax.set_xlim([0, 21])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(d_name.upper() + '\\nfinishing positions (2020-2024)', fontsize=11)\n",
    "    ax.set_xlabel('Position')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d426afce40af",
   "metadata": {},
   "source": [
    "## Posterior analysis (model 2) [0-4 pts]\n",
    "- were there any issues with the sampling? if there were what kind of ideas for mitigation were used [1 pt]\n",
    "- are the samples from posterior predictive distribution analyzed [1 pt]\n",
    " are the data consistent with posterior predictive samples and is it sufficiently commented (if they are not then is the justification provided)\n",
    "have parameter marginal disrtibutions been analyzed (histograms of individual parametes plus summaries, are they diffuse or concentrated, what can we say about values) [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15509bf581311a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:02:31.246646Z",
     "start_time": "2025-05-15T15:02:31.242522Z"
    }
   },
   "outputs": [],
   "source": [
    "model_2 = CmdStanModel(stan_file='stan/model_2.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_data = {'N': len(df),\n",
    "                'C': len([*team_id_map.values()]),\n",
    "                'E': len([*engine_id_map.values()]),\n",
    "                'D': len([*driver_id_map.values()]),\n",
    "                'Y': len([*season_id_map.values()]),\n",
    "                'driver_rating': ratings,\n",
    "                'engine': engines,\n",
    "                'constructor': teams,                \n",
    "                'driver': drivers,\n",
    "                'year': seasons,\n",
    "                'position': df['Position'] - 1} \n",
    "\n",
    "model_2_fit = model_2.sample(data=model_2_data, seed=25062025,iter_warmup=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b68600",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_names = ['hamilton', 'norris', 'max_verstappen']\n",
    "fig, axes = plt.subplots(1, len(drivers_names), figsize=(5 * len(drivers_names), 4), sharey=True)\n",
    "\n",
    "n_bins = np.arange(22) - 0.5\n",
    "\n",
    "for d_i, d_name in enumerate(drivers_names):\n",
    "    ax = axes[d_i]\n",
    "    driver_id = driver_id_map[d_name]\n",
    "    results = df[df['DriverId'] == driver_id]\n",
    "    results_idx = results.index\n",
    "\n",
    "    ax.hist((results['Position']).tolist(),\n",
    "            bins=n_bins,\n",
    "            rwidth=0.9,\n",
    "            histtype='step',\n",
    "            edgecolor='black',\n",
    "            density=True,\n",
    "            label='Observed')\n",
    "\n",
    "    ax.hist(model_2_fit.stan_variable('y_hat').T[results_idx].flatten() + 1,\n",
    "            bins=n_bins,\n",
    "            rwidth=0.9,\n",
    "            color='cornflowerblue',\n",
    "            edgecolor='royalblue',\n",
    "            alpha=0.7,\n",
    "            density=True,\n",
    "            label='Simulated')\n",
    "\n",
    "    ax.set_xticks(range(22))\n",
    "    ax.set_xlim([0, 21])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(d_name.upper() + '\\nfinishing positions (2020–2024)', fontsize=11)\n",
    "    ax.set_xlabel('Position')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc33c8583c6f282",
   "metadata": {},
   "source": [
    "## Model comaprison [0-4 pts]\n",
    "- Have models been compared using information criteria [1 pt]\n",
    "- Have result for WAIC been discussed (is there a clear winner, or is there an overlap, were there any warnings) [1 pt]\n",
    "- Have result for PSIS-LOO been discussed (is there a clear winner, or is there an overlap, were there any warnings) [1 pt]\n",
    "- Whas the model comparison discussed? Do authors agree with information criteria? Why in your opinion one model better than another [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0fd7a514f237b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:02:31.281494Z",
     "start_time": "2025-05-15T15:02:31.277472Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ccdc7fd6eb57534",
   "metadata": {},
   "source": [
    "# Driver and engine performance impact on F1 race results\n",
    "\n",
    "Łukasz Filo, Klaudiusz Grobelski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf3371f79e509c",
   "metadata": {},
   "source": [
    "## Problem formulation [0-5 pts]:\n",
    "\n",
    "- is the problem clearly stated [1 pt]\n",
    "- what is the point of creating model, are potential use cases defined [1 pt]\n",
    "- where do data comes from, what does it containt [1 pt]\n",
    "- DAG has been drawn [1 pt]\n",
    "- confoundings (pipe, fork, collider) were described [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d6ae3b36a3cdf",
   "metadata": {},
   "source": [
    "In this notebook, we will develop a Bayesian multilevel binomial regression model to predict driver performance across recent Formula 1 seasons. Specifically, we will use data from the 2019–2024 seasons. The input data includes information about drivers, constructors, and engine suppliers used by each team. The primary objective of this analysis is to understand and predict how various factors—such as driver skill, team changes, and engine suppliers—affect driver performance over time. This model could assist teams in making strategic decisions, such as evaluating whether changes in drivers or engine suppliers might enhance performance. It may also be valuable to fans and analysts seeking to assess the relative impact of technical and human factors on race results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ccc5f1",
   "metadata": {},
   "source": [
    "We use historical race data sourced from FastF1, which includes finishing positions, lap times, and team-driver pairings for each race. Driver skill ratings are obtained from the EA Sports F1 game, while engine usage data (i.e., which power unit each constructor used in a given season) is collected from Wikipedia, covering the 2019–2024 period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd831891d73c306a",
   "metadata": {},
   "source": [
    "To gain a clearer understanding of the relationships between variables and to identify potential sources of bias, we will construct a Directed Acyclic Graph (DAG)."
   ]
  },
  {
   "cell_type": "code",
   "id": "696dc5a6-6914-4d44-aa83-aeb2c4b507b9",
   "metadata": {},
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/DAG.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40b8f15b-b0a5-4c60-9fb8-fadd32357aca",
   "metadata": {},
   "source": [
    "Why these data were used:\n",
    "\n",
    "**EA Driver Rating** – an independent, available measure of skill that helps avoid subjective assessments.\n",
    "\n",
    "**Engine, Constructor** – technical foundations influencing the result, with a clear causal meaning.\n",
    "\n",
    "**Year + Constructor** – capturing variability between seasons.\n",
    "\n",
    "We omitted data such as weather, which could cause irregular effects on the model, since races in difficult conditions are hard to predict. The number of pit stops was also excluded because, in a typical race, most teams perform the same number of pit stops, or there are cases where a driver can earn an extra point for the fastest lap. If the team knows they won’t catch the driver ahead or lose position, they may perform this tactical maneuver. However, an increased number of pit stops often occurs due to collisions during the race, meaning the driver might have more pit stops but a significantly lower position. This could confuse the model’s behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3409b7bd-c00d-4a76-b5ea-265c959c5cc9",
   "metadata": {},
   "source": [
    "DAGs illustrate the main types of confounding structures:\n",
    "\n",
    "- **Pipe:** e.g., `Engine → Constructor_Performance → Race_Position` – the engine affects the constructor’s performance, which in turn influences the race position.\n",
    "\n",
    "- **Fork:** e.g., `Year → EA_Driver_Rating` and `Year → Constructor` – the year influences the driver rating (if drivers performed well that year, they have a higher rating) and also affects constructors due to changing vehicle regulations each season.\n",
    "\n",
    "- **Collider:** `Alpha_driver → Race_Position ← Constructor_Performance` – race outcome depends on both the team’s quality building the car and the skill of the driver racing it.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cf4393ef1f88c5b7",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from cmdstanpy import CmdStanModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# import logging\n",
    "# logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "904a52c401ca73b3",
   "metadata": {},
   "source": [
    "## Data preprocessing [0-2 pts]:\n",
    "- is preprocessing step clearly described [1 pt]\n",
    "- reasoning and types of actions taken on the dataset have been described [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "id": "811aaeb56d621a8f",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/processed_data/data.csv')\n",
    "unique_drivers = df['DriverId'].unique()\n",
    "driver_id_map = {driver: idx + 1 for idx, driver in enumerate(unique_drivers)}\n",
    "df['DriverId'] = df['DriverId'].map(driver_id_map)\n",
    "drivers = df['DriverId'].values\n",
    "\n",
    "unique_team = df['TeamId'].unique()\n",
    "team_id_map = {team: idx + 1 for idx, team in enumerate(unique_team)}\n",
    "df['TeamId'] = df['TeamId'].map(team_id_map)\n",
    "teams = df['TeamId'].values\n",
    "\n",
    "unique_engine = df['Engine'].unique()\n",
    "engine_id_map = {engine: idx + 1 for idx, engine in enumerate(unique_engine)}\n",
    "df['Engine'] = df['Engine'].map(engine_id_map)\n",
    "engines = df['Engine'].values\n",
    "\n",
    "unique_season = df['Season'].unique()\n",
    "season_id_map = {season: idx + 1 for idx, season in enumerate(unique_season)}\n",
    "df['Season'] = df['Season'].map(season_id_map)\n",
    "seasons = df['Season'].values\n",
    "\n",
    "\n",
    "df['Rating_all'] = (df['Rating'] - df['Rating'].mean()) / df['Rating'].std()\n",
    "ratings = df['Rating'].values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f7f4fb42",
   "metadata": {},
   "source": [
    "def standardize_group(group):\n",
    "    mean = group['Rating'].mean()\n",
    "    std = group['Rating'].std()\n",
    "    group['Rating_by_year'] = (group['Rating'] - mean) / std\n",
    "    return group\n",
    "\n",
    "df = df.groupby('Season', group_keys=False, observed=True).apply(standardize_group)\n",
    "ratings_by_year = df[\"Rating_by_year\"].values\n",
    "df['Position'] = df['Position'].astype(int)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2254b330-1e2b-4046-a839-f56956c026e9",
   "metadata": {},
   "source": [
    "In our model, we applied two approaches to standardizing driver rating data. In the first case, standardization was performed on the entire dataset, while in the second, it was done separately for each season."
   ]
  },
  {
   "cell_type": "code",
   "id": "c0105a9c",
   "metadata": {},
   "source": [
    "order_col = ['DriverId', 'Rating_by_year', 'Rating_all', 'TeamId', 'Engine', 'Season','Position']\n",
    "df = df[order_col]\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29694a230c753ff3",
   "metadata": {},
   "source": [
    "## Model [0-4 pts]\n",
    "- are two different models specified [1 pt]\n",
    "- are difference between two models explained [1 pt]\n",
    "- is the difference in the models justified (e.g. does adding aditional parameter makes sense? ) [1 pt]\n",
    "- are models sufficiently described (what are formulas, what are parameters, what data are required ) [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "id": "273e74ee-219c-49ad-afbb-eac32133739d",
   "metadata": {},
   "source": [
    "Image(\"images/model_1_DAG.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "34aa9e0e-eb38-49c5-a44b-ea20e9d2cfc9",
   "metadata": {},
   "source": [
    "### Model 1  \n",
    "  $$\n",
    "  \\text{model} = \\alpha_{\\text{constructor}} - \\alpha_{\\text{driver}} \\cdot \\text{Driver Rating}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\theta = \\mathrm{inv\\_logit}(\\text{model}) = \\frac{1}{1 + e^{-\\text{model}}}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\text{position} \\sim \\mathrm{Binomial}(n=19, p=\\theta)\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bd817-59b2-4916-a0da-e571094b6fb5",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "- **Constructor** – represents the strength of the team. It can be interpreted as a deviation from the average constructor:\n",
    "\n",
    "    - **Negative values** → better than average car  \n",
    "    - **Positive values** → worse than average car  \n",
    "\n",
    "- **Alpha_Driver** - Coefficient determining how much impact the driver has on the performance.\n",
    "\n",
    "- **Driver_Rating** - Driver's rating, taken from the EA Sports F1 video game.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ea0f4956-906e-4403-a34c-6916582c40b2",
   "metadata": {},
   "source": [
    "Image(\"images/model_2_DAG.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5475d667-9801-4fe0-b8d8-a1d416547a50",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "  $$\n",
    "  \\text{model} = \\alpha_{\\text{engine}} + \\alpha_{\\text{constructor}} - \\alpha_{\\text{driver}} \\cdot \\text{Driver Rating}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\theta = \\mathrm{inv\\_logit}(\\text{model}) = \\frac{1}{1 + e^{-\\text{model}}}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\text{position} \\sim \\mathrm{Binomial}(n=19, p=\\theta)\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bed0ee-9ca8-4f99-bf3f-469979b7cb68",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "- **Constructor** - Represents the team's strength for a given season. It can be interpreted as a deviation from the average constructor:\n",
    "\n",
    "    - **Negative values** → better than average car  \n",
    "    - **Positive values** → worse than average car  \n",
    "\n",
    "- **Engine** - Represents the engine used:\n",
    "    - **Negative values** → better than average engine  \n",
    "    - **Positive values** → worse than average engine  \n",
    "\n",
    "\n",
    "- **Alpha_Driver** - Coefficient determining how much impact the driver has on the performance.\n",
    "\n",
    "- **Driver_Rating** - Driver's rating, taken from the EA Sports F1 video game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba9decf-5805-4a04-b632-dd03ebaa8d13",
   "metadata": {},
   "source": [
    "### Difference models\n",
    "\n",
    "The difference between the first and the second model is based on two main factors. The first is the inclusion of information about the engine manufacturer used by each team. In Formula 1, there are several engine suppliers, and incorporating this parameter allows the analysis to assess how a change in engine supplier affected a team's performance. The second distinguishing factor is the inclusion of temporal parameters. In the first model, we assume that a team is generally strong or weak, whereas in the second model, we account for variations in team performance across different seasons. A well-known example for any fan is the Mercedes team, which dominated from 2014 to 2021 by winning the Constructors' Championships, but has seen a decline in performance since the 2022 season. Differences in how data is fed into the models also result from the different standardization methods used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c737263-938b-4876-8f73-7b296b372d10",
   "metadata": {},
   "source": [
    "### Required Data\n",
    "\n",
    "- Team performance data across multiple seasons (e.g., race results).  \n",
    "- Identification of constructor for each team and season.  \n",
    "- Engine manufacturer information for each team and season.\n",
    "- Driver rating data taken from the F1 game developed by EA Sports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e205422cd919ffdf",
   "metadata": {},
   "source": [
    "## Priors [0-4 pts]\n",
    "- Is it explained why particular priors for parameters were selected [1 pt]\n",
    "- Have prior predictive checks been done for parameters (are parameters simulated from priors make sense) [1 pt]\n",
    "- Have prior predictive checks been done for measurements (are measurements simulated from priors make sense) [1 pt]\n",
    "- How prior parameters were selected [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e523e4",
   "metadata": {},
   "source": [
    "## The Prior tests were prepared for the best, average, and weakest driver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d35b4d",
   "metadata": {},
   "source": [
    "### Model 1 PPC"
   ]
  },
  {
   "cell_type": "code",
   "id": "434a4759",
   "metadata": {},
   "source": [
    "model_1_ppc = CmdStanModel(stan_file='stan/model_1_ppc.stan')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f4638eb",
   "metadata": {},
   "source": [
    "def draw_plots_ppc_model_1(sigmas, driver_rating):\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "    colors = [\"#130582\", \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "\n",
    "    for s_i in range(3):\n",
    "        sigma = {'sigma': sigmas[s_i], 'driver_rating': driver_rating}\n",
    "        model_1_ppc_sim = model_1_ppc.sample(data=sigma, iter_warmup=1, fixed_param=True, seed=25062025)\n",
    "        \n",
    "        axes[s_i, 0].hist(model_1_ppc_sim.stan_variable('alpha_driver').flatten(), bins=100, density=True, color=colors[1], alpha=0.8)\n",
    "        axes[s_i, 0].set_yticks([])\n",
    "        axes[s_i, 0].set_title(f'alpha_driver ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 1].hist(model_1_ppc_sim.stan_variable('constructor').flatten(), bins=100, density=True, color=colors[2], alpha=0.8)\n",
    "        axes[s_i, 1].set_yticks([])\n",
    "        axes[s_i, 1].set_title(f'constructor ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 2].hist(model_1_ppc_sim.stan_variable('theta').flatten(), bins=100, density=True, color=colors[4], alpha=0.8)\n",
    "        axes[s_i, 2].set_yticks([])\n",
    "        axes[s_i, 2].set_title('theta = constructor - alpha_driver * driver_rating', fontweight='bold')\n",
    "\n",
    "        positions = model_1_ppc_sim.stan_variable('y_ppc').flatten() + 1\n",
    "        n_bins = np.arange(22) - 0.5\n",
    "        axes[s_i, 3].hist(positions, bins=n_bins, rwidth=0.85, density=True, color=colors[5], alpha=0.85, label=\"Simulated Positions\")\n",
    "        axes[s_i, 3].set_xticks(range(22))\n",
    "        axes[s_i, 3].set_xlim([0, 21])\n",
    "        axes[s_i, 3].set_yticks([])\n",
    "        axes[s_i, 3].set_title('Position', fontweight='bold')\n",
    "\n",
    "    for i in range(4):\n",
    "        axes[2, i].set_xlabel(['alpha_driver', 'year_constructor', 'theta', 'Position'][i], fontsize=13, fontweight='bold')\n",
    "\n",
    "    for ax_row in axes:\n",
    "        for ax in ax_row:\n",
    "            ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "    fig.suptitle(\"Prior Predictive Checks for Model 1\", fontsize=18, fontweight='bold')\n",
    "    fig.tight_layout(pad=2.0)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1dcc0a8",
   "metadata": {},
   "source": [
    "sigmas = [0.8, 1, 1.2]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45e65ae3",
   "metadata": {},
   "source": [
    "#### The driver with the best results."
   ]
  },
  {
   "cell_type": "code",
   "id": "a0569e80",
   "metadata": {},
   "source": [
    "driver_rating = 2.5\n",
    "\n",
    "draw_plots_ppc_model_1(sigmas, driver_rating)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aadbd4a8",
   "metadata": {},
   "source": [
    "#### The driver with the average results."
   ]
  },
  {
   "cell_type": "code",
   "id": "df4d2f82",
   "metadata": {},
   "source": [
    "driver_rating = 0\n",
    "\n",
    "draw_plots_ppc_model_1(sigmas, driver_rating)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a6974ec",
   "metadata": {},
   "source": [
    "#### The driver with the weakest results."
   ]
  },
  {
   "cell_type": "code",
   "id": "50570435",
   "metadata": {},
   "source": [
    "driver_rating = -2.5\n",
    "\n",
    "draw_plots_ppc_model_1(sigmas, driver_rating)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d203d85b",
   "metadata": {},
   "source": [
    "### Model 2 PPC"
   ]
  },
  {
   "cell_type": "code",
   "id": "076aeea7",
   "metadata": {},
   "source": [
    "model_2_ppc = CmdStanModel(stan_file='stan/model_2_ppc.stan')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82df1bf1",
   "metadata": {},
   "source": [
    "def draw_plots_ppc_model_2(sigmas, driver_rating):\n",
    "    fig, axes = plt.subplots(3, 5, figsize=(24, 15))\n",
    "    colors = [\"#130582\", \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "\n",
    "    for s_i in range(3):\n",
    "        sigma = {'sigma': sigmas[s_i], 'driver_rating': driver_rating}\n",
    "        model_2_ppc_sim = model_2_ppc.sample(data=sigma, iter_warmup=1, fixed_param=True, seed=25062025)\n",
    "\n",
    "        axes[s_i, 0].hist(model_2_ppc_sim.stan_variable('engine').flatten(), bins=100, density=True, color=colors[0], alpha=0.8)\n",
    "        axes[s_i, 0].set_yticks([])\n",
    "        axes[s_i, 0].set_title(f'engine ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 1].hist(model_2_ppc_sim.stan_variable('alpha_driver').flatten(), bins=100, density=True, color=colors[1], alpha=0.8)\n",
    "        axes[s_i, 1].set_yticks([])\n",
    "        axes[s_i, 1].set_title(f'alpha_driver ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 2].hist(model_2_ppc_sim.stan_variable('year_constructor').flatten(), bins=100, density=True, color=colors[2], alpha=0.8)\n",
    "        axes[s_i, 2].set_yticks([])\n",
    "        axes[s_i, 2].set_title(f'year_constructor ~ Normal(0, {sigmas[s_i]})', fontweight='bold')\n",
    "\n",
    "        axes[s_i, 3].hist(model_2_ppc_sim.stan_variable('theta').flatten(), bins=100, density=True, color=colors[4], alpha=0.8)\n",
    "        axes[s_i, 3].set_yticks([])\n",
    "        axes[s_i, 3].set_title('theta = engine + alpha_constructor_year \\n - alpha_driver * driver_rating', fontweight='bold')\n",
    "\n",
    "        positions = model_2_ppc_sim.stan_variable('y_ppc').flatten() + 1\n",
    "        n_bins = np.arange(22) - 0.5\n",
    "        axes[s_i, 4].hist(positions, bins=n_bins, rwidth=0.85, density=True, color=colors[5], alpha=0.85, label=\"Simulated Positions\")\n",
    "        axes[s_i, 4].set_xticks(range(22))\n",
    "        axes[s_i, 4].set_xlim([0, 21])\n",
    "        axes[s_i, 4].set_yticks([])\n",
    "        axes[s_i, 4].set_title('Position', fontweight='bold')\n",
    "\n",
    "    for i in range(5):\n",
    "        axes[2, i].set_xlabel(['engine', 'alpha_driver', 'year_constructor', 'theta', 'Position'][i], fontsize=13, fontweight='bold')\n",
    "\n",
    "    for ax_row in axes:\n",
    "        for ax in ax_row:\n",
    "            ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "    fig.suptitle(\"Prior Predictive Checks for Model 2\", fontsize=18, fontweight='bold')\n",
    "    fig.tight_layout(pad=2.0)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d59ca378",
   "metadata": {},
   "source": [
    "sigmas = [0.5, 0.8, 1.0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af7ace57",
   "metadata": {},
   "source": [
    "#### The driver with the best results."
   ]
  },
  {
   "cell_type": "code",
   "id": "9e0aaf39",
   "metadata": {},
   "source": [
    "driver_rating = 2.5\n",
    "\n",
    "draw_plots_ppc_model_2(sigmas, driver_rating)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9a9364e",
   "metadata": {},
   "source": [
    "#### An average driver from the middle of the field."
   ]
  },
  {
   "cell_type": "code",
   "id": "b3965e2c",
   "metadata": {},
   "source": [
    "driver_rating = 0\n",
    "\n",
    "draw_plots_ppc_model_2(sigmas, driver_rating)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1da4985b",
   "metadata": {},
   "source": [
    "#### The driver with the worst results."
   ]
  },
  {
   "cell_type": "code",
   "id": "a4c0024c",
   "metadata": {},
   "source": [
    "driver_rating = -2.5\n",
    "\n",
    "draw_plots_ppc_model_2(sigmas, driver_rating)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6bdc53b3",
   "metadata": {},
   "source": [
    "We choose sigma 0.8 for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c00465f2c09d6",
   "metadata": {},
   "source": [
    "## Posterior analysis (model 1) [0-4 pts]\n",
    "- were there any issues with the sampling? if there were what kind of ideas for mitigation were used [1 pt]\n",
    "- are the samples from posterior predictive distribution analyzed [1 pt]\n",
    "- are the data consistent with posterior predictive samples and is it sufficiently commented (if they are not then is the justification provided)\n",
    "have parameter marginal disrtibutions been analyzed (histograms of individual parametes plus summaries, are they diffuse or concentrated, what can we say about values) [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "id": "9b7eeb71ba70340e",
   "metadata": {},
   "source": [
    "model_1 = CmdStanModel(stan_file='stan/model_1.stan')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6515e04e",
   "metadata": {},
   "source": [
    "model_1_data = {'N': len(df),\n",
    "                'C': len([*team_id_map.values()]),\n",
    "                'D': len([*driver_id_map.values()]),\n",
    "                'driver_rating': ratings,\n",
    "                'constructor': teams,                \n",
    "                'driver': drivers,\n",
    "                'position': df['Position'] - 1} \n",
    "\n",
    "model_1_fit = model_1.sample(data=model_1_data, seed=25062025, iter_warmup=1000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e811405",
   "metadata": {},
   "source": [
    "drivers_names = ['ocon', 'norris', 'hamilton']\n",
    "fig, axes = plt.subplots(1, len(drivers_names), figsize=(5 * len(drivers_names), 4), sharey=True)\n",
    "\n",
    "n_bins = np.arange(22) - 0.5\n",
    "\n",
    "for d_i, d_name in enumerate(drivers_names):\n",
    "    ax = axes[d_i]\n",
    "    driver_id = driver_id_map[d_name]\n",
    "    results = df[df['DriverId'] == driver_id]\n",
    "    results_idx = results.index\n",
    "\n",
    "    ax.hist((results['Position']).tolist(),\n",
    "            bins=n_bins,\n",
    "            rwidth=0.9,\n",
    "            histtype='step',\n",
    "            edgecolor='black',\n",
    "            density=True,\n",
    "            label='Observed')\n",
    "\n",
    "    ax.hist(model_1_fit.stan_variable('y_hat').T[results_idx].flatten() + 1,\n",
    "            bins=n_bins,\n",
    "            rwidth=0.9,\n",
    "            color='cornflowerblue',\n",
    "            edgecolor='royalblue',\n",
    "            alpha=0.7,\n",
    "            density=True,\n",
    "            label='Simulated')\n",
    "\n",
    "    ax.set_xticks(range(22))\n",
    "    ax.set_xlim([0, 21])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(d_name.upper() + '\\nfinishing positions (2020-2024)', fontsize=11)\n",
    "    ax.set_xlabel('Position')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1a7d426afce40af",
   "metadata": {},
   "source": [
    "## Posterior analysis (model 2) [0-4 pts]\n",
    "- were there any issues with the sampling? if there were what kind of ideas for mitigation were used [1 pt]\n",
    "- are the samples from posterior predictive distribution analyzed [1 pt]\n",
    " are the data consistent with posterior predictive samples and is it sufficiently commented (if they are not then is the justification provided)\n",
    "have parameter marginal disrtibutions been analyzed (histograms of individual parametes plus summaries, are they diffuse or concentrated, what can we say about values) [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "id": "ff15509bf581311a",
   "metadata": {},
   "source": [
    "model_2 = CmdStanModel(stan_file='stan/model_2.stan')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc92d39e",
   "metadata": {},
   "source": [
    "model_2_data = {'N': len(df),\n",
    "                'C': len([*team_id_map.values()]),\n",
    "                'E': len([*engine_id_map.values()]),\n",
    "                'D': len([*driver_id_map.values()]),\n",
    "                'Y': len([*season_id_map.values()]),\n",
    "                'driver_rating': ratings_by_year,\n",
    "                'engine': engines,\n",
    "                'constructor': teams,                \n",
    "                'driver': drivers,\n",
    "                'year': seasons,\n",
    "                'position': df['Position'] - 1} \n",
    "\n",
    "model_2_fit = model_2.sample(data=model_2_data, seed=25062025,iter_warmup=1000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "28b68600",
   "metadata": {},
   "source": [
    "drivers_names = ['ocon', 'norris', 'hamilton']\n",
    "fig, axes = plt.subplots(1, len(drivers_names), figsize=(5 * len(drivers_names), 4), sharey=True)\n",
    "\n",
    "n_bins = np.arange(22) - 0.5\n",
    "\n",
    "for d_i, d_name in enumerate(drivers_names):\n",
    "    ax = axes[d_i]\n",
    "    driver_id = driver_id_map[d_name]\n",
    "    results = df[df['DriverId'] == driver_id]\n",
    "    results_idx = results.index\n",
    "\n",
    "    ax.hist((results['Position']).tolist(),\n",
    "            bins=n_bins,\n",
    "            rwidth=0.9,\n",
    "            histtype='step',\n",
    "            edgecolor='black',\n",
    "            density=True,\n",
    "            label='Observed')\n",
    "\n",
    "    ax.hist(model_2_fit.stan_variable('y_hat').T[results_idx].flatten() + 1,\n",
    "            bins=n_bins,\n",
    "            rwidth=0.9,\n",
    "            color='cornflowerblue',\n",
    "            edgecolor='royalblue',\n",
    "            alpha=0.7,\n",
    "            density=True,\n",
    "            label='Simulated')\n",
    "\n",
    "    ax.set_xticks(range(22))\n",
    "    ax.set_xlim([0, 21])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(d_name.upper() + '\\nfinishing positions (2020–2024)', fontsize=11)\n",
    "    ax.set_xlabel('Position')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2fc33c8583c6f282",
   "metadata": {},
   "source": [
    "## Model comaprison [0-4 pts]\n",
    "- Have models been compared using information criteria [1 pt]\n",
    "- Have result for WAIC been discussed (is there a clear winner, or is there an overlap, were there any warnings) [1 pt]\n",
    "- Have result for PSIS-LOO been discussed (is there a clear winner, or is there an overlap, were there any warnings) [1 pt]\n",
    "- Whas the model comparison discussed? Do authors agree with information criteria? Why in your opinion one model better than another [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "id": "79f0fd7a514f237b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

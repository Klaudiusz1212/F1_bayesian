{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ccdc7fd6eb57534",
   "metadata": {},
   "source": [
    "# Driver and engine performance impact on F1 race results\n",
    "\n",
    "Łukasz Filo, Klaudiusz Grobelski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf3371f79e509c",
   "metadata": {},
   "source": [
    "## Problem formulation [0-5 pts]:\n",
    "\n",
    "- is the problem clearly stated [1 pt]\n",
    "- what is the point of creating model, are potential use cases defined [1 pt]\n",
    "- where do data comes from, what does it containt [1 pt]\n",
    "- DAG has been drawn [1 pt]\n",
    "- confoundings (pipe, fork, collider) were described [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d6ae3b36a3cdf",
   "metadata": {},
   "source": [
    "In this notebook, we will develop a Bayesian multilevel binomial regression model to predict driver performance across recent Formula 1 seasons. Specifically, we will use data from the 2020–2024 seasons. The input data includes information about drivers, constructors, and engine suppliers used by each team. The primary objective of this analysis is to understand and predict how various factors—such as driver skill, team changes, and engine suppliers—affect driver performance over time. This model could assist teams in making strategic decisions, such as evaluating whether changes in drivers or engine suppliers might enhance performance. It may also be valuable to fans and analysts seeking to assess the relative impact of technical and human factors on race results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ccc5f1",
   "metadata": {},
   "source": [
    "We use historical race data sourced from FastF1, which includes finishing positions, lap times, and team-driver pairings for each race. Driver skill ratings are obtained from the EA Sports F1 game, while engine usage data (i.e., which power unit each constructor used in a given season) is collected from Wikipedia, covering the 2020–2024 period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd831891d73c306a",
   "metadata": {},
   "source": [
    "To gain a clearer understanding of the relationships between variables and to identify potential sources of bias, we will construct a Directed Acyclic Graph (DAG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696dc5a6-6914-4d44-aa83-aeb2c4b507b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/DAG.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8f15b-b0a5-4c60-9fb8-fadd32357aca",
   "metadata": {},
   "source": [
    "Why these data were used:\n",
    "\n",
    "**EA Driver Rating** – an independent, available measure of skill that helps avoid subjective assessments.\n",
    "\n",
    "**Engine, Constructor** – technical foundations influencing the result, with a clear causal meaning.\n",
    "\n",
    "**Year + Constructor** – capturing variability between seasons.\n",
    "\n",
    "We omitted data such as weather, which could cause irregular effects on the model, since races in difficult conditions are hard to predict. The number of pit stops was also excluded because, in a typical race, most teams perform the same number of pit stops, or there are cases where a driver can earn an extra point for the fastest lap. If the team knows they won’t catch the driver ahead or lose position, they may perform this tactical maneuver. However, an increased number of pit stops often occurs due to collisions during the race, meaning the driver might have more pit stops but a significantly lower position. This could confuse the model’s behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3409b7bd-c00d-4a76-b5ea-265c959c5cc9",
   "metadata": {},
   "source": [
    "DAGs illustrate the main types of confounding structures:\n",
    "\n",
    "- **Pipe:** e.g., `Engine → Constructor_Performance → Race_Position` – the engine affects the constructor’s performance, which in turn influences the race position.\n",
    "\n",
    "- **Fork:** e.g., `Year → EA_Driver_Rating` and `Year → Constructor` – the year influences the driver rating (if drivers performed well that year, they have a higher rating) and also affects constructors due to changing vehicle regulations each season.\n",
    "\n",
    "- **Collider:** `Alpha_driver → Race_Position ← Constructor_Performance` – race outcome depends on both the team’s quality building the car and the skill of the driver racing it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4393ef1f88c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cmdstanpy import CmdStanModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "from scipy.special import expit\n",
    "from numpy.random import binomial\n",
    "\n",
    "# import logging\n",
    "# logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a52c401ca73b3",
   "metadata": {},
   "source": [
    "## Data preprocessing [0-2 pts]:\n",
    "- is preprocessing step clearly described [1 pt]\n",
    "- reasoning and types of actions taken on the dataset have been described [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c2d2f",
   "metadata": {},
   "source": [
    "Data have been preprocessed in separate notebooks, which are available in the `data` directory.\n",
    "- **Data source:** FastF1, EA Sports F1 game, Wikipedia.\n",
    "- **Data merging:** Combining data from different seasons to create one large dataset.\n",
    "- **Data cleaning:** Standardizing team, driver and engine manufacturer names, removing unecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811aaeb56d621a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed_data/final_position.csv')\n",
    "\n",
    "unique_drivers = df['DriverId'].unique()\n",
    "driver_id_map = {driver: idx + 1 for idx, driver in enumerate(unique_drivers)}\n",
    "df['DriverId'] = df['DriverId'].map(driver_id_map)\n",
    "drivers = df['DriverId'].values\n",
    "\n",
    "unique_team = df['TeamId'].unique()\n",
    "team_id_map = {team: idx + 1 for idx, team in enumerate(unique_team)}\n",
    "df['TeamId'] = df['TeamId'].map(team_id_map)\n",
    "teams = df['TeamId'].values\n",
    "\n",
    "unique_engine = df['Engine'].unique()\n",
    "engine_id_map = {engine: idx + 1 for idx, engine in enumerate(unique_engine)}\n",
    "df['Engine'] = df['Engine'].map(engine_id_map)\n",
    "engines = df['Engine'].values\n",
    "\n",
    "unique_season = df['Season'].unique()\n",
    "season_id_map = {season: idx + 1 for idx, season in enumerate(unique_season)}\n",
    "df['Season'] = df['Season'].map(season_id_map)\n",
    "seasons = df['Season'].values\n",
    "\n",
    "df['Rating_all'] = (df['Rating'] - df['Rating'].mean()) / df['Rating'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_group(group):\n",
    "    mean = group['Rating'].mean()\n",
    "    std = group['Rating'].std()\n",
    "    group['Rating_by_year'] = (group['Rating'] - mean) / std\n",
    "    return group\n",
    "\n",
    "df = df.groupby('Season', group_keys=False, observed=True).apply(standardize_group)\n",
    "ratings = df['Rating_all'].values\n",
    "ratings_by_year = df[\"Rating_by_year\"].values\n",
    "df['Position'] = df['SeasonStanding'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2254b330-1e2b-4046-a839-f56956c026e9",
   "metadata": {},
   "source": [
    "In our model, we applied two approaches to standardizing driver rating data. In the first case, standardization was performed on the entire dataset, while in the second, it was done separately for each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0105a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_col = ['DriverId', 'Rating_by_year', 'Rating_all', 'TeamId', 'Engine', 'Season','Position']\n",
    "df = df[order_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29694a230c753ff3",
   "metadata": {},
   "source": [
    "## Model [0-4 pts]\n",
    "- are two different models specified [1 pt]\n",
    "- are difference between two models explained [1 pt]\n",
    "- is the difference in the models justified (e.g. does adding aditional parameter makes sense? ) [1 pt]\n",
    "- are models sufficiently described (what are formulas, what are parameters, what data are required ) [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa9e0e-eb38-49c5-a44b-ea20e9d2cfc9",
   "metadata": {},
   "source": [
    "### Model 1  \n",
    "  $$\n",
    "  \\text{model} = \\alpha_{\\text{intercept}} + \\alpha_{\\text{constructor}} + \\alpha_{\\text{driver}} \\cdot \\text{Driver Rating}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\theta = \\mathrm{inv\\_logit}(\\text{model}) = \\frac{1}{1 + e^{-\\text{model}}}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\text{position} \\sim \\mathrm{Binomial}(n=19, p=\\theta)\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"images/model1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bd817-59b2-4916-a0da-e571094b6fb5",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "- **Constructor** – represents the strength of the team. It can be interpreted as a deviation from the average constructor:\n",
    "\n",
    "    - **Positive values** → better than average car  \n",
    "    - **Negative values** → worse than average car  \n",
    "\n",
    "- **Alpha_Driver** - Coefficient determining how much impact the driver has on the performance.\n",
    "\n",
    "- **Driver_Rating** - Driver's rating, taken from the EA Sports F1 video game.\n",
    "\n",
    "- **Intercept** - Represents the baseline performance level across all seasons, teams, and drivers. It captures the average tendency of the model before adjusting for specific effects like constructor, or driver.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475d667-9801-4fe0-b8d8-a1d416547a50",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "  $$\n",
    "  \\text{model} = \\alpha_{\\text{intercept}} + \\alpha_{\\text{engine}} + \\alpha_{\\text{year\\_constructor}} + \\alpha_{\\text{driver}} \\cdot \\text{Driver Rating}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\theta = \\mathrm{inv\\_logit}(\\text{model}) = \\frac{1}{1 + e^{-\\text{model}}}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\text{position} \\sim \\mathrm{Binomial}(n=19, p=\\theta)\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"images/model2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bed0ee-9ca8-4f99-bf3f-469979b7cb68",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "- **Year_constructor** - Represents the team's strength for a given season. It can be interpreted as a deviation from the average constructor:\n",
    "\n",
    "    - **Positive values** → better than average car  \n",
    "    - **Negative values** → worse than average car  \n",
    "\n",
    "- **Engine** - Represents the engine used:\n",
    "    - **Positive values** → better than average engine  \n",
    "    - **Negative values** → worse than average engine  \n",
    "\n",
    "\n",
    "- **Alpha_Driver** - Coefficient determining how much impact the driver has on the performance.\n",
    "\n",
    "- **Driver_Rating** - Driver's rating, taken from the EA Sports F1 video game.\n",
    "\n",
    "- **Intercept** - Represents the baseline performance level across all seasons, teams, and drivers. It captures the average tendency of the model before adjusting for specific effects like engine, constructor, or driver.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba9decf-5805-4a04-b632-dd03ebaa8d13",
   "metadata": {},
   "source": [
    "### Difference between the models\n",
    "\n",
    "The difference between the first and the second model is based on two main factors. The first is the inclusion of information about the engine manufacturer used by each team. In Formula 1, there are several engine suppliers, and incorporating this parameter allows the analysis to assess how a change in engine supplier affected a team's performance. The second distinguishing factor is the inclusion of temporal parameters. In the first model, we assume that a team is generally strong or weak, whereas in the second model, we account for variations in team performance across different seasons. A well-known example for any fan is the Mercedes team, which dominated from 2014 to 2021 by winning the Constructors' Championships, but has seen a decline in performance since the 2022 season. Differences in how data is fed into the models also result from the different standardization methods used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c737263-938b-4876-8f73-7b296b372d10",
   "metadata": {},
   "source": [
    "### Required Data\n",
    "\n",
    "- Team performance data across multiple seasons (e.g., race results).  \n",
    "- Identification of constructor for each team and season.  \n",
    "- Engine manufacturer information for each team and season.\n",
    "- Driver rating data taken from the F1 game developed by EA Sports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e205422cd919ffdf",
   "metadata": {},
   "source": [
    "## Priors [0-4 pts]\n",
    "- Is it explained why particular priors for parameters were selected [1 pt]\n",
    "- Have prior predictive checks been done for parameters (are parameters simulated from priors make sense) [1 pt]\n",
    "- Have prior predictive checks been done for measurements (are measurements simulated from priors make sense) [1 pt]\n",
    "- How prior parameters were selected [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e523e4",
   "metadata": {},
   "source": [
    "## The Prior tests were prepared for the best, average, and weakest driver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d35b4d",
   "metadata": {},
   "source": [
    "### Model 1 PPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_ppc = CmdStanModel(stan_file='stan/model_1_ppc.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4638eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plots_ppc_model_1(driver_rating, positions_real):\n",
    "    fig, axes = plt.subplots(3, 5, figsize=(20, 10))\n",
    "    colors = [\"#130582\", \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "\n",
    "    for s_i in range(3):\n",
    "        sigma = {'sigma': 0.6, 'driver_rating': driver_rating[s_i]}\n",
    "        model_1_ppc_sim = model_1_ppc.sample(data=sigma, iter_warmup=1000, fixed_param=True, seed=25062025)\n",
    "\n",
    "        # alpha_driver\n",
    "        axes[s_i, 0].hist(model_1_ppc_sim.stan_variable('intercept').flatten(), bins=30, density=True, color=colors[0], alpha=0.8)\n",
    "        axes[s_i, 0].set_yticks([])\n",
    "        axes[s_i, 0].set_title(f'intercept')\n",
    "\n",
    "        # alpha_driver\n",
    "        axes[s_i, 1].hist(model_1_ppc_sim.stan_variable('alpha_driver').flatten(), bins=30, density=True, color=colors[1], alpha=0.8)\n",
    "        axes[s_i, 1].set_yticks([])\n",
    "        axes[s_i, 1].set_title(f'Driver {s_i+1}: alpha_driver')\n",
    "\n",
    "        # constructor\n",
    "        axes[s_i, 2].hist(model_1_ppc_sim.stan_variable('constructor').flatten(), bins=30, density=True, color=colors[2], alpha=0.8)\n",
    "        axes[s_i, 2].set_yticks([])\n",
    "        axes[s_i, 2].set_title('constructor')\n",
    "\n",
    "        # theta\n",
    "        axes[s_i, 3].hist(model_1_ppc_sim.stan_variable('theta').flatten(), bins=30, density=True, color=colors[4], alpha=0.8)\n",
    "        axes[s_i, 3].set_yticks([])\n",
    "        axes[s_i, 3].set_title('theta')\n",
    "\n",
    "        # simulated positions + true position\n",
    "        positions = [20 - x for x in model_1_ppc_sim.stan_variable('y_ppc').flatten()]\n",
    "        n_bins = np.arange(22) - 0.5\n",
    "        axes[s_i, 4].hist(positions, bins=n_bins, rwidth=0.85, density=True, color=colors[5], alpha=0.85, label=\"Simulated\")\n",
    "        axes[s_i, 4].set_xticks(range(1, 21))\n",
    "        axes[s_i, 4].set_xlim([0.5, 20.5])\n",
    "        axes[s_i, 4].set_yticks([])\n",
    "        axes[s_i, 4].set_title('Position')\n",
    "        true_pos = positions_real[s_i] \n",
    "        axes[s_i, 4].axvline(true_pos, color='black', linestyle='--', linewidth=2, label=\"Actual\")\n",
    "        \n",
    "    for i in range(4):\n",
    "        axes[2, i].set_xlabel(['alpha_driver', 'constructor', 'theta', 'Position'][i])\n",
    "\n",
    "    # Styl\n",
    "    for ax_row in axes:\n",
    "        for ax in ax_row:\n",
    "            ax.tick_params(axis='both', which='major')\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "    fig.suptitle(\"Prior Predictive Checks for Model 1 (with True Positions)\", fontsize=18)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751ebc3-d088-4021-98d5-d6fad96951d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2020 = df[df['Season'] == 1]\n",
    "driver_rating = year_2020['Rating_all'].tolist()\n",
    "positions_real = year_2020['Position'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e65ae3",
   "metadata": {},
   "source": [
    "#### The drivers with the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0569e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots_ppc_model_1(driver_rating[:3], positions_real[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadbd4a8",
   "metadata": {},
   "source": [
    "#### An average drivers from the middle of the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots_ppc_model_1(driver_rating[9:12], positions_real[9:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6974ec",
   "metadata": {},
   "source": [
    "#### The drivers with the weakest results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50570435",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots_ppc_model_1(driver_rating[18:21], positions_real[18:21])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203d85b",
   "metadata": {},
   "source": [
    "### Model 2 PPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076aeea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_ppc = CmdStanModel(stan_file='stan/model_2_ppc.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plots_ppc_model_2(driver_rating, positions_real):\n",
    "    fig, axes = plt.subplots(3, 6, figsize=(24, 10))\n",
    "    colors = [\"#130582\", \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\"]\n",
    "    \n",
    "    for s_i in range(3):\n",
    "        sigma = {'driver_rating': driver_rating[s_i]}\n",
    "        model_2_ppc_sim = model_2_ppc.sample(data=sigma, iter_warmup=1000, fixed_param=True, seed=25062025)\n",
    "\n",
    "        # intercept \n",
    "        axes[s_i, 0].hist(model_2_ppc_sim.stan_variable('intercept').flatten(), bins=30, density=True, color=colors[0], alpha=0.8)\n",
    "        axes[s_i, 0].set_yticks([])\n",
    "        axes[s_i, 0].set_title(f'intercept')\n",
    "\n",
    "        # engine \n",
    "        axes[s_i, 1].hist(model_2_ppc_sim.stan_variable('engine').flatten(), bins=30, density=True, color=colors[1], alpha=0.8)\n",
    "        axes[s_i, 1].set_yticks([])\n",
    "        axes[s_i, 1].set_title(f'alpha_engine')\n",
    "\n",
    "        # alpha_driver\n",
    "        axes[s_i, 2].hist(model_2_ppc_sim.stan_variable('alpha_driver').flatten(), bins=30, density=True, color=colors[2], alpha=0.8)\n",
    "        axes[s_i, 2].set_yticks([])\n",
    "        axes[s_i, 2].set_title(f'alpha_driver')\n",
    "\n",
    "        # constructor\n",
    "        axes[s_i, 3].hist(model_2_ppc_sim.stan_variable('year_constructor').flatten(), bins=30, density=True, color=colors[3], alpha=0.8)\n",
    "        axes[s_i, 3].set_yticks([])\n",
    "        axes[s_i, 3].set_title('year_constructor')\n",
    "\n",
    "        # theta\n",
    "        axes[s_i, 4].hist(model_2_ppc_sim.stan_variable('theta').flatten(), bins=30, density=True, color=colors[4], alpha=0.8)\n",
    "        axes[s_i, 4].set_yticks([])\n",
    "        axes[s_i, 4].set_title('theta')\n",
    "\n",
    "        # simulated positions + true position\n",
    "        positions = [20 - x for x in model_2_ppc_sim.stan_variable('y_ppc').flatten()]\n",
    "        n_bins = np.arange(22) - 0.5\n",
    "        axes[s_i, 5].hist(positions, bins=n_bins, rwidth=0.85, density=True, color=colors[5], alpha=0.85, label=\"Simulated\")\n",
    "        axes[s_i, 5].set_xticks(range(1, 21))\n",
    "        axes[s_i, 5].set_xlim([0.5, 20.5])\n",
    "        axes[s_i, 5].set_yticks([])\n",
    "        axes[s_i, 5].set_title('Position')\n",
    "\n",
    "        true_pos = positions_real[s_i] \n",
    "        axes[s_i, 5].axvline(true_pos, color='black', linestyle='--', linewidth=2, label=\"Actual\")\n",
    "        \n",
    "    for i in range(4):\n",
    "        axes[2, i].set_xlabel(['intercept', 'engine', 'alpha_driver', 'year_constructor', 'theta', 'Position'][i])\n",
    "\n",
    "    # Styl\n",
    "    for ax_row in axes:\n",
    "        for ax in ax_row:\n",
    "            ax.tick_params(axis='both', which='major')\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "    fig.suptitle(\"Prior Predictive Checks for Model 2 (with True Positions)\", fontsize=18)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ca378",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2020 = df[df['Season'] == 1]\n",
    "driver_rating = year_2020['Rating_by_year'].tolist()\n",
    "positions_real = year_2020['Position'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ace57",
   "metadata": {},
   "source": [
    "#### The drivers with the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0aaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots_ppc_model_2(driver_rating[:3], positions_real[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9364e",
   "metadata": {},
   "source": [
    "#### An average drivers from the middle of the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3965e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots_ppc_model_2(driver_rating[9:12], positions_real[9:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4985b",
   "metadata": {},
   "source": [
    "#### The drivers with the weakest results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots_ppc_model_2(driver_rating[18:21], positions_real[18:21])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4f122-ded8-483f-a5b2-29c8d7a780d9",
   "metadata": {},
   "source": [
    "### Prior Selection and Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8a820-5f47-45a9-849d-6516862d8b1f",
   "metadata": {},
   "source": [
    "The choice of normal priors followed van Kesteren and Bergkamp (2023), who demonstrated their suitability in hierarchical models of performance. Normal distributions were selected due to their symmetry, interpretability, and compatibility with multilevel modeling assumptions. For the all component, the prior was centered at μ = 0. For the first model, σ = 1 for both the constructor alpha, the driver alpha and the intercept. The distribution for the driver rating is HalfNormal. For the second model, μ = 0, with σ = 1 for engine, constructor and intercept. The driver is set to 0.8 based on prior predictive checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c00465f2c09d6",
   "metadata": {},
   "source": [
    "## Posterior analysis (model 1) [0-4 pts]\n",
    "- were there any issues with the sampling? if there were what kind of ideas for mitigation were used [1 pt]\n",
    "- are the samples from posterior predictive distribution analyzed [1 pt]\n",
    "- are the data consistent with posterior predictive samples and is it sufficiently commented (if they are not then is the justification provided)\n",
    "have parameter marginal disrtibutions been analyzed (histograms of individual parametes plus summaries, are they diffuse or concentrated, what can we say about values) [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f727cb",
   "metadata": {},
   "source": [
    "There was no issue with sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1308b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_post_3(model_fit, drivers_names):\n",
    "    fig, axes = plt.subplots(1, len(drivers_names), figsize=(5 * len(drivers_names), 4), sharey=True)\n",
    "\n",
    "    n_bins = np.arange(22) - 0.5\n",
    "\n",
    "    for d_i, d_name in enumerate(drivers_names):\n",
    "        ax = axes[d_i]\n",
    "        driver_id = driver_id_map[d_name]\n",
    "        results = df[(df['DriverId'] == driver_id) & (df['Season'] == 4)]\n",
    "        results_idx = results.index\n",
    "\n",
    "\n",
    "        ax.axvline(results['Position'].tolist(), color='black', linestyle='--', linewidth=2, label=\"Observed\")\n",
    "\n",
    "        ax.hist(20 - model_fit.stan_variable('y_hat').T[results_idx].flatten(),\n",
    "                bins=n_bins,\n",
    "                rwidth=0.9,\n",
    "                color='cornflowerblue',\n",
    "                edgecolor='royalblue',\n",
    "                alpha=0.7,\n",
    "                density=True,\n",
    "                label='Simulated')\n",
    "\n",
    "        ax.set_xticks(range(22))\n",
    "        ax.set_xlim([0.5, 20.5])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(d_name.upper() + '\\nfinishing positions 2023', fontsize=11)\n",
    "        ax.set_xlabel('Position')\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7eeb71ba70340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = CmdStanModel(stan_file='stan/model_1.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6515e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_data = {'N': len(df),\n",
    "                'C': len([*team_id_map.values()]),\n",
    "                'D': len([*driver_id_map.values()]),\n",
    "                'driver_rating': ratings,\n",
    "                'constructor': teams,                \n",
    "                'driver': drivers,\n",
    "                'position': 20 - df['Position']} \n",
    "\n",
    "model_1_fit = model_1.sample(data=model_1_data, seed=25062025, iter_warmup=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e811405",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_names = ['ocon', 'norris', 'hamilton']\n",
    "plot_post_3(model_1_fit, drivers_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd67c85",
   "metadata": {},
   "source": [
    "### Parameter Marginal Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49cfcc6",
   "metadata": {},
   "source": [
    "#### Alpha Driver distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a526944",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_names = ['stroll', 'bottas', 'hamilton']\n",
    "fig, axes = plt.subplots(1, len(drivers_names), figsize=(5 * len(drivers_names), 4), sharey=True)\n",
    "\n",
    "for d_i, d_name in enumerate(drivers_names):\n",
    "    driver_id = driver_id_map[d_name]\n",
    "    az.plot_posterior(model_1_fit, var_names=[\"alpha_driver\"], coords={\"alpha_driver_dim_0\": [driver_id - 1]}, ax=axes[d_i], color='cornflowerblue', hdi_prob=0.89)\n",
    "    axes[d_i].set_title(d_name.upper() + '\\nposterior alpha_driver', fontsize=11)\n",
    "\n",
    "fig.suptitle(\"Posterior alpha_driver distributions for Model 1\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698245e",
   "metadata": {},
   "source": [
    "#### Alpha constructor distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_names = ['mercedes', 'red_bull', 'haas']\n",
    "fig, axes = plt.subplots(1, len(constructor_names), figsize=(5 * len(constructor_names), 4), sharey=True)\n",
    "\n",
    "for c_i, c_name in enumerate(constructor_names):\n",
    "    constructor_id = team_id_map[c_name]\n",
    "    az.plot_posterior(model_1_fit, var_names=[\"alpha_constructor\"], coords={\"alpha_constructor_dim_0\": [constructor_id - 1]}, ax=axes[c_i], color='cornflowerblue', hdi_prob=0.89)\n",
    "    axes[c_i].set_title(c_name.upper() + '\\nposterior alpha_constructor', fontsize=11)\n",
    "\n",
    "fig.suptitle(\"Posterior alpha_constructor distributions for Model 1\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891e5fd-67f5-4ce5-998a-0ec960ca203a",
   "metadata": {},
   "source": [
    "### Driver skill trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b133b-7bac-4334-b781-35f0a9dfad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_2023 = df[df['Season'] == season_id_map[2023]][['DriverId', 'Rating_all']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf64733-af49-44bd-8c55-269ed3467a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = az.summary(model_1_fit, var_names=['alpha_driver'], kind='stats', hdi_prob=.50)\n",
    "\n",
    "driversID_in_2023 = df[df.loc[:, 'Season']==season_id_map[2023]]['DriverId'].unique()\n",
    "\n",
    "processed_driver = {\n",
    "    key.split('_')[-1].capitalize(): value\n",
    "    for key, value in driver_id_map.items()\n",
    "}\n",
    "\n",
    "driver['Driver_id'] = processed_driver.values()\n",
    "driver['Driver_name'] = processed_driver.keys()\n",
    "driver_2023 = driver[driver['Driver_id'].isin(driversID_in_2023)]\n",
    "drivers_in_2023 = driver_2023['Driver_name'].tolist()\n",
    "driver_2023 = driver_2023.merge(ratings_2023, left_on='Driver_id', right_on='DriverId', how='left')\n",
    "driver_2023['Skill_weighted_alpha'] = driver_2023['mean'] * driver_2023['Rating_all']\n",
    "driver_2023['Skill_weighted_2_5'] = driver_2023['hdi_25%'] * driver_2023['Rating_all']\n",
    "driver_2023['Skill_weighted_97_5'] = driver_2023['hdi_75%'] * driver_2023['Rating_all']\n",
    "driver_sorted = driver_2023.sort_values(by=['Skill_weighted_alpha'], ascending=True)\n",
    "driver_sorted.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df438e85-23d2-47cb-8bb8-575ef6b555c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_rating = df[['DriverId', 'Rating_all', 'Season']]\n",
    "driver_model1 = driver.merge(driver_rating, left_on='Driver_id', right_on='DriverId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74e36d-cf00-40d3-b641-65650a47bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_model1['Skill_weighted_alpha'] = driver_model1['mean'] * driver_model1['Rating_all']\n",
    "driver_model1['Skill_weighted_2_5'] = driver_model1['hdi_25%'] * driver_model1['Rating_all']\n",
    "driver_model1['Skill_weighted_97_5'] = driver_model1['hdi_75%'] * driver_model1['Rating_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e24ca8-c9fd-4aea-95b2-609f4b62b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seasons = df['Season'].nunique()\n",
    "driver_season_counts = driver_model1.groupby('DriverId')['Season'].nunique()\n",
    "drivers_in_all_seasons = driver_season_counts[driver_season_counts == n_seasons].index\n",
    "df_filtered = driver_model1[driver_model1['DriverId'].isin(drivers_in_all_seasons)]\n",
    "year_index_to_name = {v: k for k, v in season_id_map.items()}\n",
    "df_filtered['Year'] = df_filtered['Season'].map(year_index_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedb8fc-aec3-41ae-adf6-2ac5ab3d320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_filtered, col='Driver_name', col_wrap=4, height=3, sharey=True)\n",
    "\n",
    "g.map_dataframe(\n",
    "    sns.lineplot, x='Year', y='Skill_weighted_alpha', marker='o'\n",
    ")\n",
    "g.map_dataframe(\n",
    "    plt.fill_between, 'Year', 'Skill_weighted_2_5', 'Skill_weighted_97_5', alpha=0.2\n",
    ")\n",
    "g.set_axis_labels(\"Season\", \"Skill\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.fig.suptitle(\"Skill evolution by driver\", y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2c9ce-5bba-48bb-9a48-43ad4483b7b9",
   "metadata": {},
   "source": [
    "### Constructor Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f37111-1252-4455-a95e-b326a0986f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor = az.summary(model_1_fit, var_names=['alpha_constructor'], kind='stats', hdi_prob=.50)\n",
    "\n",
    "processed_teams = {\n",
    "    key.split('_')[-1].capitalize(): value\n",
    "    for key, value in team_id_map.items()\n",
    "}\n",
    "processed_teams[\"Red_Bull\"] = processed_teams.pop('Bull')\n",
    "processed_teams[\"Racing_Bulls\"] = processed_teams.pop('Rb')\n",
    "processed_teams[\"Aston_Martin\"] = processed_teams.pop('Martin')\n",
    "sorted_teams = dict(sorted(processed_teams.items(), key=lambda item: item[1]))\n",
    "\n",
    "constructor['Constructor_id'] = sorted_teams.values()\n",
    "constructor['Constructor_name'] = sorted_teams.keys()\n",
    "\n",
    "constructor_list = constructor['Constructor_name'].tolist()\n",
    "\n",
    "constructor_sorted = constructor.sort_values(by=['mean'], ascending=True)\n",
    "constructor_sorted.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb4918-381d-4b45-bb40-6d697545754a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "constructor_color = {'Ferrari': 'red', 'Mercedes': 'turquoise', 'Red_Bull': 'blue', \n",
    "                     'Williams': 'deepskyblue', 'Aston_Martin': 'darkgreen', \n",
    "                     'Racing_Bulls': 'mediumblue', 'Alpine': 'royalblue', \n",
    "                     'Sauber': 'lightgreen', 'Mclaren': 'orange', 'Haas': 'k'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for i, row in constructor_sorted.iterrows():\n",
    "    y = i\n",
    "    x_mean = row['mean']\n",
    "    x_min = row['hdi_25%']\n",
    "    x_max = row['hdi_75%']\n",
    "\n",
    "    ax.hlines(y, x_min, x_max, color=constructor_color[row['Constructor_name']], linewidth=2)\n",
    "\n",
    "    ax.plot(x_mean, y, 'o', color='teal')\n",
    "\n",
    "ax.set_yticks(range(len(constructor_sorted)))\n",
    "ax.set_yticklabels(constructor_sorted['Constructor_name'], fontsize=10)\n",
    "\n",
    "ax.set_xlabel(\"Skill\")\n",
    "ax.set_title(\"F1 Constructors Skill Ranking\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d426afce40af",
   "metadata": {},
   "source": [
    "## Posterior analysis (model 2) [0-4 pts]\n",
    "- were there any issues with the sampling? if there were what kind of ideas for mitigation were used [1 pt]\n",
    "- are the samples from posterior predictive distribution analyzed [1 pt]\n",
    "- are the data consistent with posterior predictive samples and is it sufficiently commented (if they are not then is the justification provided)\n",
    "have parameter marginal disrtibutions been analyzed (histograms of individual parametes plus summaries, are they diffuse or concentrated, what can we say about values) [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15509bf581311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = CmdStanModel(stan_file='stan/model_2.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_data = {'N': len(df),\n",
    "                'C': len([*team_id_map.values()]),\n",
    "                'E': len([*engine_id_map.values()]),\n",
    "                'D': len([*driver_id_map.values()]),\n",
    "                'Y': len([*season_id_map.values()]),\n",
    "                'driver_rating': ratings_by_year,\n",
    "                'engine': engines,\n",
    "                'constructor': teams,                \n",
    "                'driver': drivers,\n",
    "                'year': seasons,\n",
    "                'position': 20 - df['Position']} \n",
    "\n",
    "model_2_fit = model_2.sample(data=model_2_data, seed=25062025, iter_warmup=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b68600",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_names = ['ocon', 'norris', 'hamilton']\n",
    "plot_post_3(model_2_fit, drivers_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6f6c7",
   "metadata": {},
   "source": [
    "### Parameter Marginal Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd43a2d5",
   "metadata": {},
   "source": [
    "#### Alpha Driver distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_names = ['stroll', 'bottas', 'hamilton']\n",
    "fig, axes = plt.subplots(1, len(drivers_names), figsize=(5 * len(drivers_names), 4), sharey=True)\n",
    "\n",
    "for d_i, d_name in enumerate(drivers_names):\n",
    "    driver_id = driver_id_map[d_name]\n",
    "    az.plot_posterior(model_2_fit, var_names=[\"alpha_driver\"], coords={\"alpha_driver_dim_0\": [driver_id - 1]}, ax=axes[d_i], color='cornflowerblue', hdi_prob=0.89)\n",
    "    axes[d_i].set_title(d_name.upper() + '\\nposterior alpha_driver', fontsize=11)\n",
    "\n",
    "fig.suptitle(\"Posterior alpha_driver distributions for Model 2\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53135e",
   "metadata": {},
   "source": [
    "#### Alpha Construtor year distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_names = ['ferrari', 'mercedes', 'haas']\n",
    "year = 2023\n",
    "fig, axes = plt.subplots(1, len(constructor_names), figsize=(5 * len(constructor_names), 4), sharey=True)\n",
    "\n",
    "for c_i, c_name in enumerate(constructor_names):\n",
    "    constructor_id = team_id_map[c_name]\n",
    "    az.plot_posterior(model_2_fit, var_names=[\"alpha_constructor_year\"], coords={\"alpha_constructor_year_dim_0\": [season_id_map[year] - 1], \"alpha_constructor_year_dim_1\": [constructor_id - 1]}, ax=axes[c_i], color='cornflowerblue', hdi_prob=0.89)\n",
    "    axes[c_i].set_title(c_name.upper() + '\\nposterior alpha_constructor_year in ' + str(year), fontsize=11)\n",
    "\n",
    "fig.suptitle(\"Posterior alpha_constructor_year distributions for Model 2\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e55f4-9350-4e62-b3de-01ca2d48f700",
   "metadata": {},
   "source": [
    "#### Alpha Engine distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a402242-e8b9-41e9-8d00-2285dbf650e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_names = ['mercedes', 'ferrari', 'renault', 'rbpt']\n",
    "fig, axes = plt.subplots(1, len(engine_names), figsize=(5 * len(engine_names), 4), sharey=True)\n",
    "\n",
    "for c_i, c_name in enumerate(engine_names):\n",
    "    engine_id = engine_id_map[c_name]\n",
    "    az.plot_posterior(model_2_fit, var_names=[\"alpha_engine\"],coords={\"alpha_engine_dim_0\": [engine_id - 1]}, ax=axes[c_i], color='cornflowerblue', hdi_prob=0.89)\n",
    "    axes[c_i].set_title(c_name.upper() + '\\nposterior alpha_engine', fontsize=11)\n",
    "\n",
    "fig.suptitle(\"Posterior alpha_engine distributions for Model 2\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5e6623ebb54f9",
   "metadata": {},
   "source": [
    "### Driver skill trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac517b91e696aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = az.summary(model_2_fit, var_names=['alpha_driver'], kind='stats', hdi_prob=.50)\n",
    "driver['Driver_id'] = driver_id_map.values()\n",
    "driver['Driver_name'] = driver_id_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59020750ed1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_rating = df[['DriverId', 'Rating_by_year', 'Season']]\n",
    "driver_model2 = driver.merge(driver_rating, left_on='Driver_id', right_on='DriverId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74944c2833ca249",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_model2['Skill_weighted_alpha'] = driver_model2['mean'] * driver_model2['Rating_by_year']\n",
    "driver_model2['Skill_weighted_2_5'] = driver_model2['hdi_25%'] * driver_model2['Rating_by_year']\n",
    "driver_model2['Skill_weighted_97_5'] = driver_model2['hdi_75%'] * driver_model2['Rating_by_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d044663-9a2f-4ec0-8f6b-0e05126979f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_season_counts = driver_model2.groupby('DriverId')['Season'].nunique()\n",
    "drivers_in_all_seasons = driver_season_counts[driver_season_counts == n_seasons].index\n",
    "df_filtered = driver_model1[driver_model2['DriverId'].isin(drivers_in_all_seasons)]\n",
    "year_index_to_name = {v: k for k, v in season_id_map.items()}\n",
    "df_filtered['Year'] = df_filtered['Season'].map(year_index_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5757f9b2530151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_filtered, col='Driver_name', col_wrap=4, height=3, sharey=True)\n",
    "\n",
    "# Linia i cieniowanie przedziału niepewności\n",
    "g.map_dataframe(\n",
    "    sns.lineplot, x='Year', y='Skill_weighted_alpha', marker='o'\n",
    ")\n",
    "g.map_dataframe(\n",
    "    plt.fill_between, 'Year', 'Skill_weighted_2_5', 'Skill_weighted_97_5', alpha=0.2\n",
    ")\n",
    "g.set_axis_labels(\"Year\", \"Skill\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.fig.suptitle(\"Skill evolution by driver\", y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b33a26",
   "metadata": {},
   "source": [
    "### Constructor Rating in 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_indices(name):\n",
    "    match = re.match(r\"alpha_constructor_year\\[(\\d+), (\\d+)\\]\", name)\n",
    "    if match:\n",
    "        return int(match.group(1)), int(match.group(2))\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor = az.summary(model_2_fit, var_names=['alpha_constructor_year'], kind='stats', hdi_prob=.50)\n",
    "constructor = constructor.reset_index()\n",
    "\n",
    "constructor[[\"year_idx\", \"constructor_idx\"]] = constructor[\"index\"].apply(\n",
    "    lambda x: pd.Series(extract_indices(x))\n",
    ")\n",
    "\n",
    "team_index_to_name = {v - 1: k for k, v in processed_teams.items()}\n",
    "year_index_to_name = {v - 1: k for k, v in season_id_map.items()}\n",
    "\n",
    "constructor['Constructor_name'] = constructor[\"constructor_idx\"].map(team_index_to_name)\n",
    "constructor['Year'] = constructor[\"year_idx\"].map(year_index_to_name)\n",
    "\n",
    "constructor_list = constructor['Constructor_name'].tolist()\n",
    "\n",
    "constructor_2023 = constructor[constructor['Year'] == 2023]\n",
    "\n",
    "constructor_sorted = constructor_2023.sort_values(by=['mean'], ascending=True)\n",
    "constructor_sorted.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e454dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "constructor_color = {'Ferrari': 'red', 'Mercedes': 'turquoise', 'Red_Bull': 'blue', \n",
    "                     'Williams': 'deepskyblue', 'Aston_Martin': 'darkgreen', \n",
    "                     'Racing_Bulls': 'mediumblue', 'Alpine': 'royalblue', \n",
    "                     'Sauber': 'lightgreen', 'Mclaren': 'orange', 'Haas': 'k'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for i, row in constructor_sorted.iterrows():\n",
    "    y = i\n",
    "    x_mean = row['mean']\n",
    "    x_min = row['hdi_25%']\n",
    "    x_max = row['hdi_75%']\n",
    "\n",
    "    ax.hlines(y, x_min, x_max, color=constructor_color[row['Constructor_name']], linewidth=2)\n",
    "\n",
    "    ax.plot(x_mean, y, 'o', color='teal')\n",
    "\n",
    "ax.set_yticks(range(len(constructor_sorted)))\n",
    "ax.set_yticklabels(constructor_sorted['Constructor_name'], fontsize=10)\n",
    "\n",
    "ax.set_xlabel(\"Skill (lower is better)\")\n",
    "ax.set_title(\"F1 Constructors Skill Ranking in 2023\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9ac7f-11ae-46e7-bad3-a0bce821df6e",
   "metadata": {},
   "source": [
    "### Constructor trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b50443-c354-4f24-89e0-e9918c07453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(constructor, col='Constructor_name', col_wrap=4, height=3, sharey=True)\n",
    "\n",
    "# Linia i cieniowanie przedziału niepewności\n",
    "g.map_dataframe(\n",
    "    sns.lineplot, x='Year', y='mean', marker='o'\n",
    ")\n",
    "g.map_dataframe(\n",
    "    plt.fill_between, 'Year', 'hdi_25%', 'hdi_75%', alpha=0.2\n",
    ")\n",
    "g.set_axis_labels(\"Year\", \"Skill\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.fig.suptitle(\"Skill evolution by constructor (lower is better)\", y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc33c8583c6f282",
   "metadata": {},
   "source": [
    "## Model comaprison [0-4 pts]\n",
    "- Have models been compared using information criteria [1 pt]\n",
    "- Have result for WAIC been discussed (is there a clear winner, or is there an overlap, were there any warnings) [1 pt]\n",
    "- Have result for PSIS-LOO been discussed (is there a clear winner, or is there an overlap, were there any warnings) [1 pt]\n",
    "- Whas the model comparison discussed? Do authors agree with information criteria? Why in your opinion one model better than another [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a787353-4a40-44ee-9b18-b78cebe577f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_1 = az.from_cmdstanpy(posterior=model_1_fit,\n",
    "                          log_likelihood='log_lik',\n",
    "                          posterior_predictive='y_hat',\n",
    "                          observed_data=model_1_data['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cafea3d-8736-479a-a527-438a0b522230",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_2 = az.from_cmdstanpy(posterior=model_2_fit,\n",
    "                          log_likelihood='log_lik',\n",
    "                          posterior_predictive='y_hat',\n",
    "                          observed_data=model_2_data['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad5d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_compare = {\n",
    "    'Model 1': fit_1,\n",
    "    'Model 2': fit_2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ce88f",
   "metadata": {},
   "source": [
    "#### Waic comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_compare = az.compare(dict_compare, ic='waic')\n",
    "print(waic_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30185e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(waic_compare, figsize=(6, 4))\n",
    "plt.title('WAIC comparision between Model 1 and Model 2 (higher is better)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587dcff9-bc23-4c7c-a2d3-ca2cd4618149",
   "metadata": {},
   "source": [
    "Based on the WAIC comparison results, Model 2 outperforms Model 1. Model 2 has a higher expected log pointwise predictive density (elpd_waic = -206.27) compared to Model 1 (elpd_waic = -224.63), indicating better predictive accuracy. The difference in elpd_waic between the models is 18.37 in favor of Model 2.\n",
    "\n",
    "To assess the statistical significance of this difference, we calculated the ratio of elpd_diff (18.37) to its standard error (dse = 7.93), which equals approximately 2.31. This ratio suggests that Model 2 generalizes better than Model 1, although the evidence is moderate.\n",
    "\n",
    "Regarding model complexity, Model 2 has a higher effective number of parameters (p_waic = 34.29) than Model 1 (p_waic = 30.98), indicating it is more complex. Despite this, Model 2 achieves better generalization, suggesting the additional parameters improved performance.\n",
    "\n",
    "Both models generated warnings during WAIC computation, indicating potential unreliability of the WAIC estimates, likely due to the high number of parameters in each model.\n",
    "\n",
    "Finally, the model weights strongly favor Model 2 (weight = 0.88) over Model 1 (weight = 0.12), supporting the conclusion that Model 2 is the preferred model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65391e5d",
   "metadata": {},
   "source": [
    "#### Psis-loo comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_compare = az.compare(dict_compare, ic='loo')\n",
    "print(loo_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(loo_compare, figsize=(6, 4))\n",
    "plt.title('LOO comparision between Model 1 and Model 2 (higher is better)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c1abc-2b8e-4d73-ae3a-d14a612f613d",
   "metadata": {},
   "source": [
    "Based on the PSIS-LOO comparison, Model 2 outperforms Model 1. Model 2 achieves a higher expected log predictive density (elpd_loo = -215.30) compared to Model 1 (elpd_loo = -228.44), with an elpd difference of 13.15 favoring Model 2.\n",
    "\n",
    "To assess the statistical significance of this difference, we calculated the ratio of elpd_diff (13.15) to its standard error (dse = 8.28), resulting in approximately 1.59. This suggests that Model 2 generalizes better than Model 1, although the evidence is relatively weak.\n",
    "\n",
    "The effective number of parameters (p_loo) is greater for Model 2 (43.31) than for Model 1 (34.78), indicating higher complexity. Despite this increased complexity, Model 2 demonstrates better predictive performance, implying that the additional parameters contribute positively to the model.\n",
    "\n",
    "Both models issued warnings during PSIS-LOO calculations, indicating potential reliability concerns with the estimates. These warnings typically arise from influential observations or problematic data points (high Pareto k values).\n",
    "\n",
    "Finally, the model weights favor Model 2 (weight = 0.69) over Model 1 (weight = 0.31), supporting Model 2 as the preferred choice, though the strength of evidence is moderate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277dcf5-fe97-48df-a6f7-d3fc5cc6e62f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "For both information criteria, we obtained similar results that confirmed our expectations — the more complex model performs better, as we anticipated. Additionally, model 2, by incorporating information about the engine and how a given team performed in a specific year, allows for more accurate predictions regarding whether a change of engine in a particular team or a driver in a given year could improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77055d0",
   "metadata": {},
   "source": [
    "## Does the model suggest that Ocon could have achieved a better result than Perez in 2024 if he had been driving the Red Bull car?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33262b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = 'ocon'\n",
    "team = 'red_bull'\n",
    "engine = 'rbpt'\n",
    "season_driver = 2024\n",
    "season_constructor = 2024\n",
    "\n",
    "results = model_2_fit.draws_pd()\n",
    "driver_id  = driver_id_map[driver]\n",
    "constructor_id = team_id_map[team]\n",
    "engine_id = engine_id_map[engine]\n",
    "year_id_driver = season_id_map[season_driver]\n",
    "year_id_constructor = season_id_map[season_constructor]\n",
    "rating = df[(df['DriverId'] == driver_id) & (df['Season'] == year_id_driver)]['Rating_by_year'].values[0]\n",
    "\n",
    "model = (\n",
    "    results[f'alpha_constructor_year[{year_id_constructor},{constructor_id}]'] \n",
    "    + results[f'alpha_engine[{engine_id}]'] \n",
    "    - results[f'alpha_driver[{driver_id}]'] * rating\n",
    ")\n",
    "model_list = model.tolist()\n",
    "prob = expit(model_list) \n",
    "result = 20 - binomial(n=19, p=prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b0cd8-282b-4e53-9030-0c4b35292f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = 'perez'\n",
    "driver_id  = driver_id_map[driver]\n",
    "perez_2024 = df[(df['DriverId'] == driver_id) & (df['Season'] == year_id_driver)]['Position'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075d22c-6d7e-456e-a5ad-26af509288f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_ocon_readbull = np.mean(result > perez_2024)\n",
    "print(f\"P(Ocon > Perez) = {prop_ocon_readbull:.3f}\")\n",
    "print(f'According to the model, if Ocon had driven for RedBull in the 2024 season, there is a {100* prop_ocon_readbull:.1f}% probability that he would have finished the season in a\\nbetter position than Perez did in reality.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "n_bins = np.arange(22) - 0.5\n",
    "\n",
    "ax.hist(result, bins=n_bins, rwidth=0.9, color='cornflowerblue', edgecolor='royalblue', density=True, alpha=1, label='Ocon')\n",
    "ax.set_xticks(range(22))\n",
    "ax.set_xlim([0.5, 20.5])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(f'{season_driver} {driver} in {season_constructor} {team} with {engine} engine')\n",
    "ax.set_xlabel(r'position')\n",
    "ax.axvline(perez_2024, color='black', linestyle='--', linewidth=2, label=\"Perez\")\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c9d51-6b44-45eb-ad41-458380e1f85b",
   "metadata": {},
   "source": [
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770de6d6-b7a2-45d4-b1b2-b6414637c421",
   "metadata": {},
   "source": [
    "van Kesteren, E.-J., & Bergkamp, T. (2023). Bayesian analysis of Formula One race results: Disentangling driver skill and constructor advantage. Journal of Quantitative Analysis in Sports, 19(4), 273–293. https://doi.org/10.1515/jqas-2022-0021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
